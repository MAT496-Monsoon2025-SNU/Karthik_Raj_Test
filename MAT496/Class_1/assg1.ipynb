{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64dbd918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42d63342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import http.client\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebf221ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a model\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25a34532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def browse(txt: str) -> str:\n",
    "    \"\"\" Call this tool if you want to search the web for current information\"\"\"\n",
    "    \n",
    "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
    "    payload = json.dumps({\n",
    "    \"q\": txt,\n",
    "    \"gl\": \"in\"\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': os.environ.get(\"SERPER_API_KEY\"),\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "    conn.request(\"POST\", \"/search\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    #print(data.decode(\"utf-8\"))\n",
    "    data_dict = json.loads(data.decode(\"utf-8\"))\n",
    "    return data_dict['organic'][0]['snippet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc32e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [browse]\n",
    "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b9e039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a tool calling Agent by binding a list of tools to the llm\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3cd2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# This will store all converation\n",
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a chatbot. Depending on the conversation, if user demands current information, you must use the tool 'browse' to get the information. If you do not need current information, you can answer directly. Always try to keep the conversation short and crisp.\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5ca2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09bb0493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8tchqqwx2', 'function': {'arguments': '{\"txt\":\"current Prime Minister of India\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 234, 'total_tokens': 252, 'completion_time': 0.051370209, 'prompt_time': 0.019843022, 'queue_time': 0.057027368, 'total_time': 0.071213231}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b678fee8-321e-4dae-b9cd-2ffcf5696f2c-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'current Prime Minister of India'}, 'id': '8tchqqwx2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 234, 'output_tokens': 18, 'total_tokens': 252})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"Tell me about the current Prime Minister of India.\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90fe85e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me about the current Prime Minister of India.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8tchqqwx2', 'function': {'arguments': '{\"txt\":\"current Prime Minister of India\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 234, 'total_tokens': 252, 'completion_time': 0.051370209, 'prompt_time': 0.019843022, 'queue_time': 0.057027368, 'total_time': 0.071213231}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b678fee8-321e-4dae-b9cd-2ffcf5696f2c-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'current Prime Minister of India'}, 'id': '8tchqqwx2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 234, 'output_tokens': 18, 'total_tokens': 252})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a8d9b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me about the current Prime Minister of India.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8tchqqwx2', 'function': {'arguments': '{\"txt\":\"current Prime Minister of India\"}', 'name': 'browse'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 234, 'total_tokens': 252, 'completion_time': 0.051370209, 'prompt_time': 0.019843022, 'queue_time': 0.057027368, 'total_time': 0.071213231}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b678fee8-321e-4dae-b9cd-2ffcf5696f2c-0', tool_calls=[{'name': 'browse', 'args': {'txt': 'current Prime Minister of India'}, 'id': '8tchqqwx2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 234, 'output_tokens': 18, 'total_tokens': 252}),\n",
       " ToolMessage(content=\"Shri Narendra Modi was sworn-in as India's Prime Minister for the third time on 9th June 2024, following another decisive victory in the 2024 Parliamentary ...\", name='browse', tool_call_id='8tchqqwx2')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there was a tool call, execute the tool and append the tool output in the converation\n",
    "\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54341672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='20', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 311, 'total_tokens': 313, 'completion_time': 0.015686921, 'prompt_time': 0.025857881, 'queue_time': 0.051507649, 'total_time': 0.041544802}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4aa49656-1bd1-4447-82bf-622eb801d7d1-0', usage_metadata={'input_tokens': 311, 'output_tokens': 2, 'total_tokens': 313})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"What is 10 plus 10?\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc35f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa2485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
